#!/usr/bin/env python3

import argparse
import json
import os
import sys
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), ".."))

from src.constants import *
from src.funcs_common import CustomHelpFormatter, view_config_file, isint, get_start_time_msg, get_true_option, \
                             get_cdcbench_version, get_elapsed_time_msg, get_object_name, \
                             print_description_msg, print_complete_msg, print_error_msg, \
                             exec_database_error
from src.funcs_datamaker import data_file_name, FuncsDataMake
from src.funcs_dml import FuncsDml
from src.mgr_config import ConfigManager
from src.mgr_connection import ConnectionManager
from src.mgr_logger import LoggerManager
from src.mgr_mappers import MapperManager

from datetime import datetime
from sqlalchemy.exc import DatabaseError

# Working Directory를 cdcbench로 변경
os.chdir(os.path.join(os.path.dirname(os.path.realpath(__file__)), ".."))

parser = argparse.ArgumentParser(prog="cdcbench", usage="%(prog)s [option...][argument...]", allow_abbrev=False,
                                 formatter_class=lambda prog: CustomHelpFormatter(prog, max_help_position=18))

data_category_group = parser.add_mutually_exclusive_group()
dml_group = parser.add_mutually_exclusive_group()

data_category_group.add_argument("-S", "--string", action="store_true",
                                 help=f"specifies table to {STRING_TEST}.")

data_category_group.add_argument("-N", "--numeric", action="store_true",
                                 help=f"specifies table to {NUMERIC_TEST}.")

data_category_group.add_argument("-D", "--datetime", action="store_true",
                                 help=f"specifies table to {DATETIME_TEST}.")

data_category_group.add_argument("-B", "--binary", action="store_true",
                                 help=f"specifies table to {BINARY_TEST}.")

data_category_group.add_argument("-L", "--lob", action="store_true",
                                 help=f"specifies table to {LOB_TEST}.")

data_category_group.add_argument("-O", "--oracle", action="store_true",
                                 help=f"specifies table to {ORACLE_TEST}.")

data_category_group.add_argument("-Q", "--sqlserver", action="store_true",
                                 help=f"specifies table to {SQLSERVER_TEST}.")

data_category_group.add_argument("-U", "--user-table", action="store",
                                 help=f"specifies table to user defined table.")

dml_group.add_argument("-i", "--insert", action="store", metavar="<number of data>", type=int,
                       help="insert data in the specified table.")

dml_group.add_argument("-u", "--update", action="store", nargs="*", metavar="ID_value",
                       type=int, help="update data in the specified table.")

dml_group.add_argument("-d", "--delete", action="store", nargs="*", metavar="ID_value",
                       type=int, help="delete data in the specified table.")

parser.add_argument("-c", "--commit", action="store", metavar="<commit units>", type=int,
                    help="specifies the commit unit.")

parser.add_argument("-s", "--single", action="store_true",
                    help="change to single insert. (-i/--insert is required)")

parser.add_argument("-r", "--rollback", action="store_true",
                    help="rollback the entered data.")

parser.add_argument("-C", "--columns", action="store", nargs="+", metavar="column id (or name)",
                    type=lambda item: int(item) if isint(item) else item,
                    help="specifies the column in which want to perform DML "
                         "(cannot use a combination of column_id and column_name)")

parser.add_argument("-w", "--where", action="store",
                    help="specify the update or delete conditions (ex. --update --where \"product_id = 1\")")

parser.add_argument("-sep", "--separate-tx", action="store", metavar="column id (or name)",
                    type=lambda column: int(column) if isint(column) else column,
                    help="separate transactions based on the specified column (--where option required)")

parser.add_argument("-f", "--config", action="store", nargs="?", metavar="Configuration File",
                    const=default_config_name, help="view or select configuration file.")

parser.add_argument("-v", "--verbose", action="store_false",
                    help="display the progress of the operation.")

parser.add_argument("-V", "--version", action="version", version=get_cdcbench_version(),
                    help="print CDCBENCH\'s version.")

args = parser.parse_args()

# 아무 옵션도 없을 경우 예외처리
if not args.string and not args.numeric and not args.datetime and not args.binary and not args.lob \
   and not args.oracle and not args.sqlserver and args.user_table is None \
   and args.insert is None and args.update is None and args.delete is None \
   and args.commit is None and not args.single and not args.rollback and args.columns is None \
   and args.where is None and args.separate_tx is None \
   and args.config is None and args.verbose:
    parser.print_help()
    parser.exit(1)

# --rollback 옵션이 DML Group 옵션없이 사용될 경우 예외처리
elif args.rollback and (args.insert is None and args.update is None and args.delete is None):
    parser.error("--rollback option is required --insert/--update/--delete option\n")

# --verbose 옵션이 DML Group 옵션없이 사용될 경우 예외처리
elif not args.verbose and (args.insert is None and args.update is None and args.delete is None):
    parser.error("--verbose option is required --insert/--update/--delete option\n")

# --single 옵션이 --insert 옵션없이 사용될 경우 예외처리
elif args.insert is None and args.single:
    parser.error("--single option is required --insert option\n")

# --columns 옵션이 --delete 옵션과 함께 사용될 경우 예외처리
elif args.columns is not None and args.delete is not None:
    parser.error("--columns option cannot be used with --delete option\n")

# --commit 옵션이 --where 옵션과 함께 사용될 경우 예외처리
elif args.commit is not None and args.where is not None:
    parser.error("--commit option cannot be used with --where option\n")

# --separate-tx 옵션이 --where 옵션없이 사용될 경우 예외처리
elif args.separate_tx is not None and args.where is None:
    parser.error("--separate-tx option is required --where option\n")

# --user-table 옵션 인자로 Sample Table이 입력될 경우 예외처리
elif args.user_table is not None and args.user_table.upper() in sample_tables:
    parser.error("--user-table option are not available as sample tables\n")

# --columns 옵션에 자료형이 섞여서 저장될 경우 예외처리
if args.columns is not None:
    if all(isinstance(item, int) for item in args.columns):
        pass
    elif all(isinstance(item, str) for item in args.columns):
        pass
    else:
        parser.error("The specified column list is of unsupported format")

val_err_msg = "{} option's second argument is less than first argument"

# --update 옵션 인자 개수별 처리
if args.update is not None:
    if len(args.update) == 0:
        args.update = "nowhere"
    elif len(args.update) == 1:
        args.update = [args.update[0], args.update[0]]
    elif len(args.update) == 2:
        if args.update[0] <= args.update[1]:
            pass
        else:
            parser.error(val_err_msg.format("--update"))
    else:
        parser.error("--update option's argument is allowed up to two argument")

# --delete 옵션 인자 개수별 처리
if args.delete is not None:
    if len(args.delete) == 0:
        args.delete = "nowhere"
    elif len(args.delete) == 1:
        args.delete = [args.delete[0], args.delete[0]]
    elif len(args.delete) == 2:
        if args.delete[0] <= args.delete[1]:
            pass
        else:
            parser.error(val_err_msg.format("--delete"))
    else:
        parser.error("--delete option's argument is allowed up to two argument")

config = None
logger = None
sql_logger = None

try:

    config = ConfigManager(args.config)

    # CUBRID, Tibero일 경우 기능 제한
    if config.source_dbms_type == CUBRID or config.source_dbms_type == TIBERO:
        print_error_msg("This feature is not available on CUBRID/TIBERO")

    # Log Level 설정 및 Logger 획득
    LoggerManager.set_log_level(config.log_level)
    logger = LoggerManager.get_logger(__file__)
    
    # SQL Log Level 설정 및 Logger 획득
    LoggerManager.set_sql_log_level(config.sql_log_level)
    sql_logger = LoggerManager.get_sql_logger()

    logger.info(f"Module {__file__} is started")

    # --config 옵션을 제외한 다른 옵션이 없을 경우 해당 Config 내용을 출력
    if not args.string and not args.numeric and not args.datetime and not args.binary and not args.lob \
       and not args.oracle and not args.sqlserver and args.user_table is None \
       and args.insert is None and args.update is None and args.delete is None \
       and args.commit is None and not args.single and not args.rollback and args.columns is None \
       and args.where is None and args.separate_tx is None \
       and args.verbose:
        print(view_config_file(config.get_config()))
        logger.info(f"Load configuration file ({config.config_name})")
        logger.info(json.dumps(config.get_config(), indent=4))
        parser.exit(1)

    logger.info(f"Load configuration file ({config.config_name})")
    logger.info(json.dumps(config.get_config(), indent=4))

    # 각 DBMS별 고유 데이터 타입이 포함된 테이블인 경우 source_dbms_type 값 체크
    if args.oracle is True and (config.source_dbms_type != ORACLE):
        parser.error("Source DBMS is not Oracle.")
    elif args.sqlserver is True and (config.source_dbms_type != SQLSERVER):
        parser.error("Source DBMS is not SQL Server.")

    selected_table_name = get_true_option({STRING_TEST: args.string, NUMERIC_TEST: args.numeric,
                                           DATETIME_TEST: args.datetime, BINARY_TEST: args.binary, LOB_TEST: args.lob,
                                           ORACLE_TEST: args.oracle, SQLSERVER_TEST: args.sqlserver,
                                           args.user_table: args.user_table})

    if selected_table_name is None:
        selected_table_name = get_true_option(
            {INSERT_TEST: args.insert, UPDATE_TEST: args.update, DELETE_TEST: args.delete}
        )

    if selected_table_name == UPDATE_TEST:
        args.columns = ["COL_NAME"]

    conn = ConnectionManager(config.get_src_conn_info())  # Connection Instance 생성

    mapper = MapperManager(conn, [selected_table_name]).get_mappers()  # Mapper Instance 생성

    dml = FuncsDml(conn)  # Functions Instance 생성

    table = mapper.metadata.tables[get_object_name(selected_table_name, mapper.metadata.tables.keys())]

    all_columns = table.columns

    def get_inspected_columns(column_items, all_columns):

        if column_items is None:
            return [column for column in all_columns if column.default is None]
        else:
            columns = []
            if all(isinstance(item, int) for item in column_items):
                column_names = all_columns.keys()
                for column_id in column_items:
                    if column_id <= 0:
                        print_error_msg(f"Invalid Column ID. [{column_id}]")
                    try:
                        columns.append(all_columns[column_names[column_id - 1]])
                    except IndexError:
                        print_error_msg(f"The column is a column that does not exist in the table. [{column_id}]")
            else:
                for column_name in column_items:
                    try:
                        columns.append(get_object_name(column_name, all_columns.keys()))
                    except KeyError:
                        print_error_msg(f"The column is a column that does not exist in the table. [{column_name}]")

            return columns

    selected_columns = get_inspected_columns(args.columns, all_columns)

    if selected_table_name in [table for table in sample_tables]:
        data_maker = FuncsDataMake(data_file_name[selected_table_name.split("_")[0].upper()])
    elif args.user_table is not None:
        data_maker = FuncsDataMake(data_file_name["USER"])
    else:
        data_maker = None

    # --commit 옵션 인자 처리
    if args.commit is None:
        args.commit = 1000

    if args.insert:

        print(get_start_time_msg(datetime.now()))
        print_description_msg("INSERT", table, args.verbose)
        logger.info(f"Start data insert in the \"{table}\" Table")

        insert_info_msg = f"Insert Information: {{\"Table Name\" : {table}, " \
                          f"\"Number of Data\": {args.insert}, \"Commit Unit\": {args.commit}}}"

        logger.info(insert_info_msg)

        if args.single:

            class Table(mapper):
                __table__ = mapper.metadata.tables[get_object_name(selected_table_name, mapper.metadata.tables.keys())]
                column_names = list(column.name for column in __table__.c)

                def __init__(self, **kwargs):
                    data = kwargs["data"]
                    for column_name in data.keys():
                        setattr(self, self.column_names[self.column_names.index(column_name)], data[column_name])

            result = dml.single_insert(Table, selected_columns, args.insert, args.commit, data_maker,
                                       args.rollback, args.verbose)
        else:
            result = dml.multi_insert(table, selected_columns, args.insert, args.commit, data_maker,
                                      args.rollback, args.verbose)

        print_complete_msg(args.rollback, args.verbose, separate=False)

        elapse_time_msg = get_elapsed_time_msg(result["end_time"], result["start_time"])
        print(f"  {elapse_time_msg}")
        logger.info(elapse_time_msg)

        logger.info(f"End data insert in the \"{INSERT_TEST}\" Table")

    elif args.update:

        update_info_msg = f"Update Information: {{\"Table Name\" : {table}, " \
                          f"\"Updated Columns\": {args.columns}, " \
                          f"\"Where Clause\": {args.where} }}"

        logger.info(update_info_msg)

        print(get_start_time_msg(datetime.now()))
        print_description_msg("UPDAT", table, args.verbose)
        logger.info(f"Start data update in the \"{table}\" Table")

        if args.update == "nowhere" and args.where is None:
            result = dml.update(table, selected_columns, args.where, data_maker, args.rollback, args.verbose,
                                nowhere=True)
        elif args.separate_tx is not None:
            where_column = get_inspected_columns([args.separate_tx], all_columns)[0]
            result = dml.separated_update(table, selected_columns, args.where, where_column, data_maker,
                                          args.rollback, args.verbose)
        elif args.where is not None:
            result = dml.update(table, selected_columns, args.where, data_maker, args.rollback, args.verbose)
        else:
            args.where = f"{args.update[0]} <= T_ID AND T_ID <= {args.update[1]}"
            where_column = get_inspected_columns(["T_ID"], all_columns)[0]
            result = dml.separated_update(table, selected_columns, args.where, where_column, data_maker,
                                          args.rollback, args.verbose, args.commit)

        print_complete_msg(args.rollback, args.verbose, separate=False)

        elapse_time_msg = get_elapsed_time_msg(result["end_time"], result["start_time"])
        print(f"  {elapse_time_msg}")
        logger.info(elapse_time_msg)

        logger.info(f"End data update in the \"{table}\" Table")

    elif args.delete:

        delete_info_msg = f"Delete Information: {{\"Table Name\" : {table}, \"Where Clause\": {args.where}}}"
        logger.info(delete_info_msg)

        print(get_start_time_msg(datetime.now()))
        print_description_msg("DELET", table, args.verbose)
        logger.info(f"Start data delete in the \"{table}\" Table")

        if args.delete == "nowhere" and args.where is None:
            result = dml.delete(table, args.where, args.rollback, args.verbose, nowhere=True)
        elif args.separate_tx is not None:
            where_column = get_inspected_columns([args.separate_tx], all_columns)[0]
            result = dml.separated_delete(table, args.where, where_column, args.rollback, args.verbose)
        elif args.where is not None:
            result = dml.delete(table, args.where, args.rollback, args.verbose)
        else:
            args.where = f"{args.delete[0]} <= T_ID AND T_ID <= {args.delete[1]}"
            where_column = get_inspected_columns(["T_ID"], all_columns)[0]
            result = dml.separated_delete(table, args.where, where_column, args.rollback, args.verbose, args.commit)

        print_complete_msg(args.rollback, args.verbose, separate=False)

        elapse_time_msg = get_elapsed_time_msg(result["end_time"], result["start_time"])
        print(f"  {elapse_time_msg}")
        logger.info(elapse_time_msg)

        logger.info(f"End data delete in the \"{table}\" Table")

except DatabaseError as dberr:
    exec_database_error(logger, config.log_level, dberr, fail_print=False)

except KeyboardInterrupt:
    print(f"\n{__file__}: warning: operation is canceled by user")
    exit(1)

finally:
    print()
    if logger is not None:
        logger.info(f"Module {__file__} is ended\n")

    if sql_logger is not None:
        sql_logger.info("\n")
